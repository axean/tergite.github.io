{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Puhuri-Tergite playground\n",
        "---"
      ],
      "id": "a8cd303c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is just a playgorund as we try to connect Tergite to Puhuri\n",
        "\n",
        "\n",
        "## GLOBAL VARIABLES\n",
        "\n",
        "The following gloabl variables should be set to the right values. **HOWEVER, NEVER COMMIT YOUR SECRETS TO GIT**\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "import enum\n",
        "import pprint\n",
        "\n",
        "import pydantic\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "from typing import Any, Dict, Optional, Tuple, List\n",
        "\n",
        "from motor import motor_asyncio\n",
        "from pymongo import UpdateOne\n",
        "from waldur_client import WaldurClient, ComponentUsage\n",
        "\n",
        "# The User-set variables\n",
        "WALDUR_URI = \"https://access.nordiquest.net/api/\"\n",
        "WALDUR_TOKEN = \"<API key of your user, click on the user in the navbar>\"\n",
        "PROVIDER_UUID = \"<Unique ID of the Service provider for QAL900, visit the service provider detail page and get the uuid in the URL box>\"\n",
        "# this requires one to install mongodb. Or you can set it to \"\" or None and it will be ignored\n",
        "MONGODB_URI = \"mongodb://localhost:27017\"\n",
        "\n",
        "\n",
        "# Puhuri Waldur client\n",
        "CLIENT = WaldurClient(WALDUR_URI, WALDUR_TOKEN)\n",
        "DB_CLIENT: Optional[motor_asyncio.AsyncIOMotorClient] = None\n",
        "if MONGODB_URI:\n",
        "    DB_CLIENT = motor_asyncio.AsyncIOMotorClient(MONGODB_URI)\n",
        "    DB_NAME = \"your-database\"\n",
        "    PROJECTS_COLLECTION = \"projects\"\n",
        "\n",
        "# Exceptions\n",
        "\n",
        "class BaseQal9000Exception(Exception):\n",
        "    def __init__(self, message: str = \"\"):\n",
        "        self._message = message\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}: {self._message}\"\n",
        "\n",
        "    def __str__(self):\n",
        "        return self._message if self._message else self.__class__.__name__\n",
        "\n",
        "class ResourceNotFoundError(BaseQal9000Exception):\n",
        "    \"\"\"Raised when no resources are found\"\"\"\n",
        "\n",
        "class ComponentNotFoundError(BaseQal9000Exception):\n",
        "    \"\"\"Raised when no component is found\"\"\"\n",
        "\n",
        "class PlanPeriodNotFoundError(BaseQal9000Exception):\n",
        "    \"\"\"Raised when no plan period is found\"\"\"\n",
        "```\n",
        "\n",
        "### Puhuri Entity Layout\n",
        "\n",
        "![Puhuri-qal9000-entity-layout](../assets/puhuri-entity-layout.png)\n",
        "\n",
        "## Database Schemas\n",
        "\n",
        "There are a few database schemas we may need. We are using mongodb here, but any kind of storage can be used/\n",
        "\n",
        "```python\n",
        "class ProjectSource(str, enum.Enum):\n",
        "    PUHURI = 'puhuri'\n",
        "    INTERNAL = 'internal'\n",
        "\n",
        "class Project(pydantic.BaseModel):\n",
        "    # ...\n",
        "    ext_id: str  # the project_uuid in this case\n",
        "    source: ProjectSource\n",
        "    user_emails: List[str] = []\n",
        "    qpu_seconds: int = 0\n",
        "    is_active: bool = True\n",
        "    resource_ids: List[str] = []\n",
        "```\n",
        "\n",
        "## Operations\n",
        "\n",
        "There are some important operations we need to pull off. They include:\n",
        "\n",
        "- Report usage on a per-project basis for projects that have Tergite offerings\n",
        "- Retrieve latest approved resource allocations that have Tergite offerings from puhuri\n",
        "- Retrieve latest users added to given projects that have Tergite offerings from puhuri\n",
        "\n",
        "### Project-based Usage Report Submission\n",
        "\n",
        "The flow of logic is as shown below\n",
        "\n",
        "![Puhuri-qal9000-report-usage](../assets/puhuri-resource-usage-reporting-flow.png)\n",
        "\n",
        "#### Retrieving Resources of a Given Project\n",
        "\n",
        "We should be able to retrieve all resources attached to a project by running the cell below.\n",
        "\n",
        "**Note that we need to first approve all pending orders for this provider. This ensures that all resources that we will query later have 'plan periods'. (We should have updated our projects lists first)**\n",
        "\n",
        "Only resources with approved orders have plan periods. \n",
        "\n",
        "Resources associated with approved orders have state \"OK\". This is something we will filter for later.\n",
        "\n",
        "```python\n",
        "# Set the UUID of the project whose resources you wish to inspect\n",
        "PROJECT_UUID = \"\"\n",
        "\n",
        "_resource_filter = {\"provider_uuid\": PROVIDER_UUID, \"state\": \"OK\"}\n",
        "if PROJECT_UUID:\n",
        "    _resource_filter[\"project_uuid\"] = PROJECT_UUID\n",
        "\n",
        "# If you don't set the PROJECT_UUID, all resources that have offerings from\n",
        "# your given service provider will appear here\n",
        "_RESOURCES = CLIENT.filter_marketplace_resources(_resource_filter)\n",
        "_RESOURCES\n",
        "```\n",
        "\n",
        "Let us check if there are any resources and exit with an error if none are found\n",
        "\n",
        "```python\n",
        "if len(_RESOURCES) == 0:\n",
        "    raise ResourceNotFoundError(f\"no resource found for provider and project\")\n",
        "```\n",
        "\n",
        "#### Separate Limit-based From Usage-based Resources\n",
        "\n",
        "Since Tergite keeps track of only the project uuid, and yet a project can have multiple resources, we need to determine\n",
        "the resource against which our usage report is to be made.\n",
        "\n",
        "Currently, we think we should consume **limit-based** resources first before we move on to the usage-based resources.  \n",
        "Limit-based resources are those that are prepaid i.e. can only be used after a given amount of QPU minutes has been purchased.  \n",
        "On the other hand, usage-based resources are billed, say at the end of the month.\n",
        "\n",
        "We therefore need to separate limit-based resources of a project from usage-based resources and only report usage on the \n",
        "usage-based resources if there is no limit-based resource.\n",
        "\n",
        "\n",
        "Question: What should we do if all limit-based resources are depleted yet there are some usage-based resources? (_Probably report on the usage-based resources_)\n",
        "\n",
        "```python\n",
        "_USAGE_BASED_RESOURCES = []\n",
        "_LIMIT_BASED_RESOURCES = []\n",
        "\n",
        "for resource in _RESOURCES:\n",
        "    # usage-based resources have an empty {} as their limits\n",
        "    if len(resource[\"limits\"]) == 0:\n",
        "        _USAGE_BASED_RESOURCES.append(resource)\n",
        "    else:\n",
        "        _LIMIT_BASED_RESOURCES.append(resource)\n",
        "\n",
        "print(\"USAGE BASED RESOURCES\")\n",
        "pprint.pprint(_USAGE_BASED_RESOURCES)\n",
        "\n",
        "print(\"LIMIT BASED RESOURCES\")\n",
        "pprint.pprint(_LIMIT_BASED_RESOURCES)\n",
        "```\n",
        "\n",
        "#### Selecting the Right Resource to Report Usage Against\n",
        "\n",
        "We are going to look through the different resources and select the right resource to report usage against.\n",
        "\n",
        "```python\n",
        "# the QPU seconds to be reported against the selected resource\n",
        "_QPU_SECONDS_USED = 80\n",
        "\n",
        "# the resource whose usage is to be updated\n",
        "_SELECTED_RESOURCE: Optional[Dict[str, Any]] = None\n",
        "\n",
        "# the accounting component to use when send resource usage.\n",
        "# Note: project -> many resources -> each with an (accounting) plan -> each with multiple (accounting) components\n",
        "_SELECTED_COMPONENT: Optional[Dict[str, Any]] = None\n",
        "\n",
        "# the limit-based resources have a dictionary of \"limits\" with keys as the \"internal names\" or \"types\" of the components\n",
        "# and the values as the maximum amount for that component. This amount is in units of that component\n",
        "# e.g. 10 for one component, might mean 10 days, while for another it might mean 10 minutes depending\n",
        "# on the 'measurement_unit' of that component.\n",
        "# We will select the component whose limit (in seconds) >= the usage\n",
        "_SELECTED_COMPONENT_TYPE: Optional[str] = None\n",
        "```\n",
        "\n",
        "**NOTE: We are making a big assumption that when creating components in the puhuri UI, the 'measurement unit's \n",
        "set on the component are of the following possible values: 'second', 'hour', 'minute', 'day', 'week', 'half_month', and 'month'.**\n",
        "\n",
        "We attempt to get the first limit-based resource that has a limit value (in seconds) greater or equal to the `_QPU_SECONDS_USED` to be reported.\n",
        "This is only polite to the customer so that we don't run one resource to below zero while the others are one way above zero.\n",
        "\n",
        "```python\n",
        "def get_accounting_component(\n",
        "        offering_uuid: str, \n",
        "        component_type: str, \n",
        "        cache: Optional[Dict[Tuple[str, str], Dict[str, Any]]] = None,\n",
        "        ) -> Dict[str, Any]:\n",
        "    \"\"\"Gets the accounting component given the component type and the offering_uuid\n",
        "    \n",
        "    If the caches are provided, it attempts to extract the component \n",
        "    from the cache if the cache is provided\n",
        "\n",
        "    Args:\n",
        "        offering_uuid: the UUID string of the offering the component belongs to\n",
        "        component_type: the type of the component\n",
        "        cache: the dictionary cache that holds components, \n",
        "            accessible by (offering_uuid, component_type) tuple\n",
        "\n",
        "    Returns:\n",
        "        the component\n",
        "    \"\"\"\n",
        "    _cache = cache if isinstance(cache, dict) else {}\n",
        "    component = _cache.get((offering_uuid, component_type))\n",
        "\n",
        "    if component is None:\n",
        "        offering = CLIENT.get_marketplace_provider_offering(offering_uuid)\n",
        "        _cache.update({(offering_uuid, v[\"type\"]): v for v in offering[\"components\"]})\n",
        "        component = _cache[(offering_uuid, component_type)]\n",
        "\n",
        "    return component\n",
        "    \n",
        "\n",
        "# A map to help convert limits and amounts to-and-fro seconds given a particular accounting component\n",
        "_COMPONENT_UNIT_SECONDS_MAP: Dict[str, int] = {\n",
        "    \"month\": 30 * 24 * 3_600,\n",
        "    \"half_month\": 15 * 24 * 3_600,\n",
        "    \"week\": 7 * 24 * 3_600,\n",
        "    \"day\": 24 * 3_600,\n",
        "    \"hour\": 3_600,\n",
        "    \"minute\": 60,\n",
        "    \"second\": 1,\n",
        "}\n",
        "\n",
        "_COMPONENTS_CACHE: Dict[Tuple[str, str], Dict[str, Any]] = {}\n",
        "\n",
        "for resource in _LIMIT_BASED_RESOURCES:\n",
        "    offering_uuid = resource[\"offering_uuid\"]\n",
        "\n",
        "    for comp_type, comp_amount in resource[\"limits\"].items():\n",
        "        component = get_accounting_component(\n",
        "            offering_uuid=offering_uuid, component_type=comp_type, cache=_COMPONENTS_CACHE)\n",
        "\n",
        "        unit_value = _COMPONENT_UNIT_SECONDS_MAP[component[\"measured_unit\"]]\n",
        "        limit_in_seconds = comp_amount * unit_value\n",
        "\n",
        "        # select resource which has at least one limit (or purchased QPU seconds) \n",
        "        # greater or equal to the seconds to be reported.\n",
        "        if limit_in_seconds >= _QPU_SECONDS_USED:\n",
        "            _SELECTED_RESOURCE = resource\n",
        "            _SELECTED_COMPONENT = component\n",
        "            _SELECTED_COMPONENT_TYPE = comp_type\n",
        "            break\n",
        "\n",
        "    # get out of loop once we have a selected resource\n",
        "    if _SELECTED_RESOURCE is not None:\n",
        "        break\n",
        "\n",
        "print(\"_SELECTED_RESOURCE\")\n",
        "pprint.pprint(_SELECTED_RESOURCE)\n",
        "\n",
        "print(\"_SELECTED_COMPONENT_TYPE\")\n",
        "pprint.pprint(_SELECTED_COMPONENT_TYPE)\n",
        "\n",
        "print(\"_SELECTED_COMPONENT\")\n",
        "pprint.pprint(_SELECTED_COMPONENT)\n",
        "```\n",
        "\n",
        "If no limit-based resource has enough QPU minutes, we select the first usage-based resource.\n",
        "If no usage-based resource exists, we select the first limit-based resource. \n",
        "\n",
        "Of course if there are no resources at all, we should have not reached this far! We should have exited, with an error already.\n",
        "\n",
        "```python\n",
        "if _SELECTED_RESOURCE is None:\n",
        "    try:\n",
        "        _SELECTED_RESOURCE = _USAGE_BASED_RESOURCES[0]\n",
        "    except IndexError:\n",
        "        _SELECTED_RESOURCE = _LIMIT_BASED_RESOURCES[0]\n",
        "\n",
        "_SELECTED_RESOURCE\n",
        "```\n",
        "\n",
        "#### Getting the Right Component Type\n",
        "\n",
        "We need to get the corresponding accounting component type to use to report usage. \n",
        "If we got a limit-based resource, we should have already set the `_SELECTED_COMPONENT_TYPE` basing on the key in the `limits`\n",
        "dict that had an amount greater or equal to the QPU minutes we are going to report.\n",
        "\n",
        "**Remember that `limits` is a dict containing the component types and their corresponding limits**\n",
        "\n",
        "If  `_SELECTED_COMPONENT_TYPE` is not yet set, we need to obtain the first component type in the offering associated\n",
        "with the selected resource.\n",
        "\n",
        "Let us first get the offering that is associcated with the selected resource\n",
        "\n",
        "```python\n",
        "# This should not be necessary if you already have _SELECTED_COMPONENT_TYPE set\n",
        "if _SELECTED_COMPONENT_TYPE is None:\n",
        "    _SELECTED_OFFERING = CLIENT.get_marketplace_provider_offering(_SELECTED_RESOURCE[\"offering_uuid\"])\n",
        "\n",
        "    _SELECTED_OFFERING\n",
        "```\n",
        "\n",
        "If offering has no components, we raise an exception and exit\n",
        "\n",
        "```python\n",
        "# This should not be necessary if you already have _SELECTED_COMPONENT_TYPE set\n",
        "if _SELECTED_COMPONENT_TYPE is None:\n",
        "    _components = _SELECTED_OFFERING[\"components\"]\n",
        "    if len(_components) == 0:\n",
        "        raise ComponentNotFoundError(\"no components found for the selected offering\")\n",
        "    \n",
        "    _SELECTED_COMPONENT = _components[0]\n",
        "    _SELECTED_COMPONENT_TYPE = _SELECTED_COMPONENT[\"type\"]\n",
        "```\n",
        "\n",
        "#### Generate a Usage Report\n",
        "\n",
        "We now need to generate the usage report to send over to puhuri\n",
        "\n",
        "Let us create a function to convert the QPU seconds into the component unit e.g \"hour\", \"month\" e.t.c\n",
        "\n",
        "```python\n",
        "def to_measured_unit(qpu_seconds: float, measured_unit: str) -> float:\n",
        "    \"\"\"Converts the qpu seconds into the given measured unit of the component\n",
        "     \n",
        "    measured_unit e.g. hour, day etc\n",
        "    \n",
        "    Args:\n",
        "        qpu_seconds: the QPU seconds to convert\n",
        "        measured_unit: the 'measured_unit' of the accounting component\n",
        "\n",
        "    Returns:\n",
        "        the QPU time in 'measured_unit's\n",
        "    \"\"\"\n",
        "    # round up to two decimal places\n",
        "    return round(qpu_seconds / _COMPONENT_UNIT_SECONDS_MAP[measured_unit], 2)\n",
        "```\n",
        "\n",
        "And then the usage report.\n",
        "\n",
        "##### Get the Plan Period for the Selected Resource\n",
        "\n",
        "In order to send the usage report, one must sent the plan preiod UUID for the given resource.\n",
        "**Note that only resources whose orders have been approved (or ar in state 'OK'), have associated planned periods.**\n",
        "\n",
        "Let's retrieve the plan periods for the selected resource\n",
        "\n",
        "```python\n",
        "_PLAN_PERIODS = CLIENT.marketplace_resource_get_plan_periods(resource_uuid=_SELECTED_RESOURCE[\"uuid\"])\n",
        "\n",
        "_PLAN_PERIODS\n",
        "```\n",
        "\n",
        "We now need to get the plan period for the current month. We may not be sure\n",
        "whether there is only one plan period for this month or not so we will get the last one in the list for this month.\n",
        "\n",
        "Let's first create some datetime utility functions\n",
        "\n",
        "```python\n",
        "def to_datetime(timestamp: str) -> datetime:\n",
        "    \"\"\"converts a timestamp of format like 2024-01-10T14:32:05.880079Z to datetime\n",
        "    \n",
        "    Args:\n",
        "        timestamp: the timestamp string\n",
        "\n",
        "    Returns:\n",
        "        the datetime corresponding to the given timestamp string\n",
        "    \"\"\"\n",
        "    return datetime.fromisoformat(timestamp.replace(\"Z\", \"+00:00\"))\n",
        "\n",
        "\n",
        "def is_in_month(\n",
        "    month_year: Tuple[int, int],\n",
        "    timestamp: str,\n",
        ") -> bool:\n",
        "    \"\"\"Checks if the given timestamp is in the given month\n",
        "\n",
        "    Note that months start at 1 i.e. January = 1, February = 2, ...\n",
        "\n",
        "    Args:\n",
        "        month_year: the (month, year) pair\n",
        "        timestamp: the timestamp string in format like 2024-01-10T14:32:05.880079Z\n",
        "\n",
        "    Returns:\n",
        "        True if the timestamp belongs to the same month, False if otherwise\n",
        "    \"\"\"\n",
        "    timestamp_date = to_datetime(timestamp)\n",
        "    month, year = month_year\n",
        "    return timestamp_date.month == month and timestamp_date.year == year\n",
        "```\n",
        "\n",
        "Now let's get the plan periods for the current month\n",
        "\n",
        "```python\n",
        "_NOW = datetime.now(tz=timezone.utc)\n",
        "_SELECTED_PLAN_PERIOD: Optional[Dict[str, Any]] = None\n",
        "\n",
        "_PLAN_PERIODS_FOR_CURRENT_MONTH = [\n",
        "    v for v in _PLAN_PERIODS \n",
        "    if is_in_month((_NOW.month, _NOW.year), v[\"start\"])\n",
        "]\n",
        "\n",
        "try:\n",
        "    _SELECTED_PLAN_PERIOD = _PLAN_PERIODS_FOR_CURRENT_MONTH[-1]\n",
        "except IndexError:\n",
        "    raise PlanPeriodNotFoundError(f\"no plan period was found for month: {(_NOW.month, _NOW.year)}, for resource {_SELECTED_RESOURCE['uuid']}\")\n",
        "\n",
        "_SELECTED_PLAN_PERIOD\n",
        "```\n",
        "\n",
        "##### Submit the Usage Report\n",
        "\n",
        "We are now ready to submit the usage report.\n",
        "\n",
        "We will create a component usage for the first plan period of that given resource.\n",
        "\n",
        "```python\n",
        "# requests.post(_USAGE_REPORT_URL, data=_USAGE_REPORT_PAYLOAD, headers=_USAGE_REPORT_HEADERS)\n",
        "usage = ComponentUsage(\n",
        "    type= _SELECTED_COMPONENT_TYPE,\n",
        "    amount=to_measured_unit(\n",
        "    800, measured_unit=_SELECTED_COMPONENT[\"measured_unit\"]),\n",
        "    description= f\"{_QPU_SECONDS_USED} QPU seconds\",\n",
        ")\n",
        "\n",
        "CLIENT.create_component_usages(plan_period_uuid=_SELECTED_PLAN_PERIOD[\"uuid\"], \n",
        "                               usages=[usage])\n",
        "```\n",
        "\n",
        "#### Puhuri Waldur Constraint: 1 Usage Per Month\n",
        "\n",
        "When we try again to submit another usage for the same plan, we may see that no new usage item is added to the 'components' of the plan period. To see this, you will have to run the previous code cell, the run the code cell before that.\n",
        "\n",
        "As of now it seems like Puhuri can only accept 1 usage per month. This might change in future but for now, we must accumulate usages internally, and send the accumulated data\n",
        "\n",
        "This means that only one request is expected per day. Any requests sent within that month (say 2024-01) will overwrite the previous entry for that month.\n",
        "\n",
        "##### How to Work With Constraint\n",
        "\n",
        "We will have to log every usage internally every month as a separate usage. We expect only one usage report for each job ID.\n",
        "Now and again, at whatever interval we wish, we will compute the accumulated usage for the current month and project and send it over to the Puhuri waldur server.\n",
        "\n",
        "**We do not have to wait for a month to elapse in order to resend usage reports for the same resource, (or plan) since it will be overwritten.**\n",
        "\n",
        "For us to limit access to users who have gone beyond the current limit for a given project, we might need to get the current pending QPUs left \n",
        "basing on the accumulated usage we have internally in Tergite, vs the allocated QPU seconds.\n",
        "\n",
        "## Getting List of New Projects\n",
        "\n",
        "We also need to get all new projects that have been created that are requesting for a resource governed by this service provider.\n",
        "\n",
        "\n",
        "### Get All New Resources\n",
        "\n",
        "We first get all the new resources attached to this provider uuid\n",
        "\n",
        "```python\n",
        "_NEW_RESOURCES = CLIENT.filter_marketplace_resources({\n",
        "    \"provider_uuid\": PROVIDER_UUID,\n",
        "    \"state\": \"Creating\"\n",
        "})\n",
        "\n",
        "_NEW_RESOURCES\n",
        "```\n",
        "\n",
        "From these resources, we can extract the unique individual project UUID's that are attached to these resources, and upsert them into our databases as new `Project` instances\n",
        "\n",
        "First of all we need to group the resources by project UUID.\n",
        "\n",
        "_Note that a given pre-existing project can order new resources. When updating the database, we should upsert in such a way that we increment the prexisting `qpu_seconds` for any project that exists or we create a new project._\n",
        "\n",
        "Let's group the new resources by project UUID. We will sum their \"limit\"s and \"limit_usage\"\n",
        "\n",
        "```python\n",
        "class PuhuriProjectMetadata(pydantic.BaseModel):\n",
        "    \"\"\"Metadata as extracted from Puhuri resources\"\"\"\n",
        "    uuid: str \n",
        "    # dict of offering_uuid and limits dict\n",
        "    limits: Dict[str, Dict[str, float]] = {}\n",
        "    # dict of offering_uuid and limit_usage dict\n",
        "    limit_usage: Dict[str, Dict[str, float]] = {}\n",
        "    resource_uuids: List[str]\n",
        "\n",
        "\n",
        "def remove_nones(data: Dict[str, Optional[Any]], __new: Any):\n",
        "    \"\"\"Replaces None values with the replacement\n",
        "    \n",
        "    Args:\n",
        "        data: the dictionary whose None values are to be replaced\n",
        "        __new: the replacement for the None values\n",
        "\n",
        "    Returns:\n",
        "        the dictionary with the None values replaced with the replacement\n",
        "    \"\"\"\n",
        "    return {k: v if v is not None else __new for k, v in data.items()}\n",
        "\n",
        "\n",
        "def extract_project_metadata(resources: List[Dict[str, Any]]) -> List[PuhuriProjectMetadata]:\n",
        "    \"\"\"Extracts the project metadata from a list of resources\n",
        "    \n",
        "    A project can contan any number of resources so we need to group the resources\n",
        "    by project UUID and aggregate any relevant fields like \"limits\" and \"limit_usage\"\n",
        "\n",
        "    Args:\n",
        "        resources: the list of resource dictionaries\n",
        "\n",
        "    Returns:\n",
        "        list of PuhuriProjectMetadata\n",
        "    \"\"\"\n",
        "    results: Dict[str, PuhuriProjectMetadata] = {}\n",
        "\n",
        "    for resource in resources:\n",
        "        offering_uuid = resource[\"offering_uuid\"]\n",
        "        project_uuid = resource[\"project_uuid\"]\n",
        "        limits = remove_nones(resource[\"limits\"], 0)\n",
        "        limit_usage = remove_nones(resource[\"limit_usage\"], 0)\n",
        "        project_meta = PuhuriProjectMetadata(\n",
        "                uuid=project_uuid,\n",
        "                limits={offering_uuid: limits},\n",
        "                limit_usage={offering_uuid: limit_usage},\n",
        "                resource_uuids=[resource[\"uuid\"]],\n",
        "            )\n",
        "        original_meta = results.get(project_uuid, None)\n",
        "        \n",
        "        if isinstance(original_meta, PuhuriProjectMetadata):\n",
        "            original_limits = original_meta.limits.get(offering_uuid, {})\n",
        "            project_meta.limits[offering_uuid] = {\n",
        "                k: v + original_limits.get(k, 0)\n",
        "                for k, v in limits.items() \n",
        "            }\n",
        "\n",
        "            original_usages = original_meta.limit_usage.get(offering_uuid, {})\n",
        "            project_meta.limit_usage[offering_uuid] = {\n",
        "                k: v + original_usages.get(k, 0)\n",
        "                for k, v in limit_usage.items() \n",
        "            }\n",
        "\n",
        "            project_meta.resource_uuids.extend(original_meta.resource_uuids)\n",
        "\n",
        "        results[project_uuid] = project_meta\n",
        "\n",
        "    return list(results.values())\n",
        "\n",
        "_NEW_PROJECT_METADATA = extract_project_metadata(_NEW_RESOURCES)\n",
        "\n",
        "_NEW_PROJECT_METADATA\n",
        "```\n",
        "\n",
        "#### Compute the QPU seconds for each project\n",
        "\n",
        "Before we can update our database, we need to compute the QPU seconds for each project.\n",
        "\n",
        "Let's create a function to do just that\n",
        "\n",
        "```python\n",
        "def get_qpu_seconds(metadata: PuhuriProjectMetadata) -> float:\n",
        "    \"\"\"Computes the net QPU seconds the project is left with\n",
        "    \n",
        "    Args:\n",
        "        metadata: the metadata of the project\n",
        "\n",
        "    Returns:\n",
        "        the net QPU seconds, i.e. allocated minus used\n",
        "    \"\"\"\n",
        "    net_qpu_seconds = 0\n",
        "    _components_cache: Dict[Tuple[str, str], Dict[str, Any]] = {}\n",
        "\n",
        "    for offering_uuid, limits in metadata.limits.items():\n",
        "        limit_usage = metadata.limit_usage.get(offering_uuid, {})\n",
        "\n",
        "        for comp_type, comp_amount in limits.items():\n",
        "            component = get_accounting_component(\n",
        "                offering_uuid=offering_uuid, component_type=comp_type, cache=_components_cache)\n",
        "\n",
        "            unit_value = _COMPONENT_UNIT_SECONDS_MAP[component[\"measured_unit\"]]\n",
        "            net_comp_amount = comp_amount - limit_usage.get(comp_type, 0)\n",
        "            net_qpu_seconds += (net_comp_amount * unit_value)\n",
        "\n",
        "    return net_qpu_seconds\n",
        "```\n",
        "\n",
        "We can now extract `Project` instances from the `PuhuriProjectMetadata`\n",
        "\n",
        "```python\n",
        "_NEW_PROJECTS: List[Project] = [Project(\n",
        "    ext_id=item.uuid,\n",
        "    source=ProjectSource.PUHURI,\n",
        "    qpu_seconds=get_qpu_seconds(item),\n",
        "    is_active=False,\n",
        "    resource_ids=item.resource_uuids,\n",
        ") for item in _NEW_PROJECT_METADATA]\n",
        "\n",
        "_NEW_PROJECTS\n",
        "```\n",
        "\n",
        "#### Upsert the New Projects into Database\n",
        "\n",
        "We now have to upsert the new projects into the database.\n",
        "\n",
        "Remember, if any of the projects already exist, we should increment their QPU seconds; and their `is_active` set to `False` momentarily.\n",
        "\n",
        "_Notice that we have not yet approved the above orders. However, all these new projects are set to `is_active`=False, until their orders are approved. This is after they are inserted into the database._\n",
        "\n",
        "First, let us create a unique Index for the project `ext_id` in the projects database collection. This is to ensure that no project has more than one entry.\n",
        "\n",
        "_SideNote: [beanie ODM](https://beanie-odm.dev/) can be a good tool to use to create database models that have indexes_\n",
        "\n",
        "```python\n",
        "# if using mongo db\n",
        "if DB_CLIENT:\n",
        "    _db: motor_asyncio.AsyncIOMotorDatabase = DB_CLIENT[DB_NAME]\n",
        "    _collection: motor_asyncio.AsyncIOMotorCollection = _db[PROJECTS_COLLECTION]\n",
        "\n",
        "    await _collection.create_index(\"ext_id\", unique=True)\n",
        "```\n",
        "\n",
        "Then we will update our projects\n",
        "\n",
        "```python\n",
        "# if using mongo db\n",
        "if DB_CLIENT:\n",
        "    _db: motor_asyncio.AsyncIOMotorDatabase = DB_CLIENT[DB_NAME]\n",
        "    _collection: motor_asyncio.AsyncIOMotorCollection = _db[PROJECTS_COLLECTION]\n",
        "\n",
        "    _responses = await asyncio.gather(*(_collection.update_one({\n",
        "            \"ext_id\": project.ext_id, \n",
        "            # a guard to ensure projects whose order approvals keep\n",
        "            # failing do not have their qpu_seconds incremented indefinitely\n",
        "            # NOTE: this may fail with a Conflict Error if any of the resource_ids \n",
        "            #   already exists in the project. You might need to resolve this manually\n",
        "            \"resource_ids\": {\"$nin\": project.resource_ids},\n",
        "            }, {\n",
        "            \"$set\": {\n",
        "                \"source\": ProjectSource.PUHURI.value,\n",
        "                \"is_active\": project.is_active,\n",
        "            },\n",
        "            \"$inc\": {\n",
        "                \"qpu_seconds\": project.qpu_seconds,\n",
        "            },\n",
        "            \"$addToSet\": {\"resource_ids\": {\"$each\": project.resource_ids}}\n",
        "        }, upsert=True) for project in _NEW_PROJECTS), return_exceptions=True)\n",
        "    \n",
        "    _UPDATED_PROJECTS = [\n",
        "        _NEW_PROJECTS[index]\n",
        "        for index, resp in enumerate(_responses)\n",
        "        if not isinstance(resp, Exception)\n",
        "    ]\n",
        "    \n",
        "\n",
        "    pprint.pprint(_UPDATED_PROJECTS)\n",
        "```\n",
        "\n",
        "#### Approve All Orders for the given resources\n",
        "\n",
        "We will then approve all the orders for the new resources and when successful, we will activate their associated projects\n",
        "\n",
        "We will first create a function to do the approvals\n",
        "\n",
        "```python\n",
        "async def approve_pending_orders(client: WaldurClient, provider_uuid: str, **kwargs) -> Dict[str, Any]:\n",
        "    \"\"\"Approves all orders for the given service provider that are in the 'pending-provider' state\n",
        "\n",
        "    Args:\n",
        "        client: the WaldurClient\n",
        "        provider_uuid: the UUID string of the service provider\n",
        "        kwargs: extra filters for filtering the orders\n",
        "\n",
        "    Returns:\n",
        "        dictionary of kwargs used to filter orders.\n",
        "\n",
        "    Raises:\n",
        "        WaldurClientException: error making request\n",
        "        ValueError: no order item found for filter {kwargs}\n",
        "    \"\"\"\n",
        "    # This function does not have to be asynchronous in this notebook\n",
        "    # but it needs to be asynchronous in web-servers so that it does not\n",
        "    # block other requests. Same thing for all other functions that make\n",
        "    # network calls.\n",
        "    loop = asyncio.get_event_loop()\n",
        "\n",
        "    filter_obj = {\n",
        "        'state': 'pending-provider',\n",
        "        'provider_uuid': provider_uuid,\n",
        "        **kwargs\n",
        "    }\n",
        "    order_items = await loop.run_in_executor(None, client.list_orders, filter_obj)\n",
        "    if len(order_items) == 0:\n",
        "        raise ValueError(f\"no order item found for filter {kwargs}\")\n",
        "    \n",
        "    await asyncio.gather(*(loop.run_in_executor(None, client.marketplace_order_approve_by_provider, order[\"uuid\"]) \n",
        "                      for order in order_items),)\n",
        "    return kwargs\n",
        "```\n",
        "\n",
        "Then we can make the API calls to Puhuri top approve the pending orders\n",
        "\n",
        "```python\n",
        "# if using mongo db\n",
        "if DB_CLIENT:\n",
        "    _RESOURCE_UUID_PROJECT_UUID_MAP = {\n",
        "        resource_uuid: project.ext_id\n",
        "        for project in _UPDATED_PROJECTS\n",
        "        for resource_uuid in project.resource_ids\n",
        "    }\n",
        "    pprint.pprint(_RESOURCE_UUID_PROJECT_UUID_MAP)\n",
        "\n",
        "    # _results is a list of Dict[resource_uuid, str]\n",
        "    # Note that we are filtering by resource UUID, not project UUID, because there is a chance \n",
        "    # that a project could have added new resources while we were still processing the \n",
        "    # current ones\n",
        "    _responses = await asyncio.gather(*(\n",
        "        approve_pending_orders(CLIENT, PROVIDER_UUID, resource_uuid=resource_uuid)\n",
        "        for resource_uuid in _RESOURCE_UUID_PROJECT_UUID_MAP.keys()\n",
        "    ), return_exceptions=True)\n",
        "\n",
        "    _APPROVED_RESOURCE_UUID_MAPS = [resp for resp in _responses if isinstance(resp, dict)]\n",
        "\n",
        "\n",
        "    pprint.pprint(_APPROVED_RESOURCE_UUID_MAPS)\n",
        "```\n",
        "\n",
        "We then have to get all approved projects i.e. projects without a non-approved order\n",
        "\n",
        "```python\n",
        "# if using mongo db\n",
        "if DB_CLIENT:\n",
        "    _results_map = {item[\"resource_uuid\"]: True for item in _APPROVED_RESOURCE_UUID_MAPS}\n",
        "\n",
        "    # approved projects are those that have all their resources approved\n",
        "    _APPROVED_PROJECT_UUIDS = [\n",
        "        metadata.uuid for metadata in _NEW_PROJECT_METADATA\n",
        "        if all(_results_map.get(resource_uuid) for resource_uuid in metadata.resource_uuids)\n",
        "    ]\n",
        "\n",
        "    pprint.pprint(_APPROVED_PROJECT_UUIDS)\n",
        "```\n",
        "\n",
        "Then we update the approved projects in the database by setting their `is_active` to `True`.\n",
        "\n",
        "Note that some projects might have been active before new orders were queried. But then due to a failing order approval, they suddenly become inactive. That order must be resolved before they are reactivated, on the next run.\n",
        "\n",
        "**Otherwise, no new resources will be added to that project**\n",
        "\n",
        "```python\n",
        "# if using mongo db\n",
        "if DB_CLIENT:\n",
        "    _db: motor_asyncio.AsyncIOMotorDatabase = DB_CLIENT[DB_NAME]\n",
        "    _collection: motor_asyncio.AsyncIOMotorCollection = _db[PROJECTS_COLLECTION]\n",
        "\n",
        "    # set the approved projects' \"is_active\" to True\n",
        "    _result = await _collection.bulk_write(\n",
        "        [UpdateOne({\n",
        "            \"ext_id\": ext_id, \n",
        "            }, {\n",
        "            \"$set\": {\n",
        "                \"is_active\": True,\n",
        "            }\n",
        "        }) \n",
        "         for ext_id in _APPROVED_PROJECT_UUIDS]\n",
        "    )\n",
        "\n",
        "    pprint.pprint(_result)\n",
        "```\n",
        "\n",
        "## Updating QPU Seconds for Each Pre-existing Project\n",
        "\n",
        "We need to update the allocated QPU seconds for all projects. This is like taking a snapshot of Puhuri's state at a given time and transfering it to QAL9000.\n",
        "\n",
        "We should first of all get all approved resources. This should ideally be done after approving all pending orders (i.e. after updating the project list in Tergite).\n",
        "\n",
        "```python\n",
        "_APPROVED_RESOURCES = CLIENT.filter_marketplace_resources({\n",
        "    \"provider_uuid\": PROVIDER_UUID,\n",
        "    \"state\": \"OK\"\n",
        "})\n",
        "\n",
        "_APPROVED_RESOURCES\n",
        "```\n",
        "\n",
        "We are assuming that all projects allocated to QAL9000 in puhuri will be \"limit-based\", as this allows us to restrict usage of the quantum computer once \n",
        "the limits for the allocation have been exhausted.\n",
        "\n",
        "**However, we are not able to stop any one from creating a 'usage-based' resource and attaching it to QAL9000. We will thus keep the qpu_seconds of such projects at 0 hence no access to their members.**\n",
        "\n",
        "In future, this could change. For instance, we could begin tracking whether a project is 'usage-based' or 'limit-based' within QAL9000. And then update the authorization logic to allow users whose projects are 'usage-based' even when their qpu_seconds is <= 0\n",
        "\n",
        "Let us now add up all the net `qpu_seconds` for each project (since a project can have multiple resources).\n",
        "\n",
        "We do this by grouping the resources into `PuhuriProjectMetadata`.\n",
        "\n",
        "```python\n",
        "_ALL_PROJECT_METADATA = extract_project_metadata(_APPROVED_RESOURCES)\n",
        "\n",
        "_ALL_PROJECT_METADATA\n",
        "```\n",
        "\n",
        "Then we compute the QPU seconds of each project from the `PuhuriProjectMetadata`\n",
        "\n",
        "```python\n",
        "_ALL_PROJECTS: List[Project] = [Project(\n",
        "    ext_id=item.uuid,\n",
        "    source=ProjectSource.PUHURI,\n",
        "    qpu_seconds=get_qpu_seconds(item),\n",
        "    is_active=True,\n",
        "    resource_ids=item.resource_uuids,\n",
        ") for item in _ALL_PROJECT_METADATA]\n",
        "\n",
        "_ALL_PROJECTS\n",
        "```\n",
        "\n",
        "We then update the database; replacing the QPU seconds for each project with the new one.\n",
        "\n",
        "```python\n",
        "# if using mongo db\n",
        "if DB_CLIENT:\n",
        "    _db: motor_asyncio.AsyncIOMotorDatabase = DB_CLIENT[DB_NAME]\n",
        "    _collection: motor_asyncio.AsyncIOMotorCollection = _db[PROJECTS_COLLECTION]\n",
        "\n",
        "    _responses = await asyncio.gather(*(_collection.update_one({\n",
        "            \"ext_id\": project.ext_id, \n",
        "            # a guard to ensure that no resource is ignored\n",
        "            # NOTE: this may fail with a Conflict Error if any of the resource_ids \n",
        "            #   does not already exist in the project. You might need to resolve this manually\n",
        "            \"resource_ids\": {\"$in\": project.resource_ids},\n",
        "            }, \n",
        "            {\n",
        "                \"$set\": {\n",
        "                    \"source\": ProjectSource.PUHURI.value,\n",
        "                    \"is_active\": project.is_active,\n",
        "                    \"qpu_seconds\": project.qpu_seconds,\n",
        "                    \"resource_ids\": project.resource_ids,\n",
        "                },\n",
        "            }, \n",
        "        upsert=True) for project in _ALL_PROJECTS), return_exceptions=True)\n",
        "    \n",
        "    _ALL_UPDATED_PROJECTS = [\n",
        "        _ALL_PROJECTS[index]\n",
        "        for index, resp in enumerate(_responses)\n",
        "        if not isinstance(resp, Exception)\n",
        "    ]\n",
        "    \n",
        "\n",
        "    pprint.pprint(_ALL_UPDATED_PROJECTS)\n",
        "```\n",
        "\n",
        "### Ensuring Idempotency\n",
        "\n",
        "We do not upsert in this case.\n",
        "\n",
        "Any projects whose approved resources have changed between the last time the database was updated with new `resource_uuid`s and now, will not be updated by this routine.\n",
        "\n",
        "It should be updated by the routine that deals with new resource allocations.\n",
        "\n",
        "## Updating List of Users Attached to Projects\n",
        "\n",
        "We also need to be able to get all users that are all given projects recently.\n",
        "\n",
        "Preferably, it would be better to get any new user attachments as opposed to scanning all projects every single time. However, this seems like it is not possible at this time.\n",
        "\n",
        "### Get All Approved Resources\n",
        "\n",
        "So we need to first get all approved resources. This should ideally be done after approving all pending orders (i.e. after we have updated the project list in Tergite with the new orders).\n",
        "\n",
        "```python\n",
        "\n",
        "_APPROVED_RESOURCES = CLIENT.filter_marketplace_resources({\n",
        "    \"provider_uuid\": PROVIDER_UUID,\n",
        "    \"state\": \"OK\"\n",
        "})\n",
        "\n",
        "_APPROVED_RESOURCES\n",
        "```\n",
        "\n",
        "### Get the Teams for Each Approved Resource\n",
        "\n",
        "For each approved resource, we extract the teams and associate them with the project_uuid for that resource\n",
        "\n",
        "```python\n",
        "# A map of project_uuid and the list of users attached to it\n",
        "_PROJECTS_USERS_MAP = {\n",
        "    resource[\"project_uuid\"]: CLIENT.marketplace_resource_get_team(resource[\"uuid\"])\n",
        "    for resource in _APPROVED_RESOURCES\n",
        "}\n",
        "\n",
        "_PROJECTS_USERS_MAP\n",
        "```\n",
        "\n",
        "We can them update our databases with the new projects users, ensuring to overwrite any existing user lists for any project, while closing all puhuri-attached projects that we have at we have in QAL9000 that have no users anymore.\n",
        "\n",
        "This requires that we tag every project in QAL9000 with a 'source' attribute so that we are able to extract those that are from Puhuri (i.e. with source='puhuri').\n",
        "\n",
        "```python\n",
        "# if using mongo db\n",
        "if DB_CLIENT:\n",
        "    _db: motor_asyncio.AsyncIOMotorDatabase = DB_CLIENT[DB_NAME]\n",
        "    _collection: motor_asyncio.AsyncIOMotorCollection = _db[PROJECTS_COLLECTION]\n",
        "\n",
        "    await _collection.bulk_write(\n",
        "        [UpdateOne({\n",
        "            \"ext_id\": project_id, \n",
        "            \"source\": ProjectSource.PUHURI.value,\n",
        "            }, {\n",
        "            \"$set\": {\n",
        "                \"user_emails\": [user[\"email\"] for user in user_list],\n",
        "            }\n",
        "        }) \n",
        "         for project_id, user_list in _PROJECTS_USERS_MAP.items()]\n",
        "    )\n",
        "```\n",
        "\n",
        "### Ensuring Idempotency\n",
        "\n",
        "We do not upsert in this case. We just replace the user_emails field with the new lists\n",
        "\n",
        "This also requires that we bulk update all projects whose 'external ID'  are not IN the list of keys from `_PROJECTS_USERS_MAP` and yet have 'source' = 'puhuri'\n",
        "\n",
        "```python\n",
        "# if using mongo db\n",
        "if DB_CLIENT:\n",
        "    _db: motor_asyncio.AsyncIOMotorDatabase = DB_CLIENT[DB_NAME]\n",
        "    _collection: motor_asyncio.AsyncIOMotorCollection = _db[PROJECTS_COLLECTION]\n",
        "\n",
        "    \n",
        "    _filter_obj = {\n",
        "        \"source\": ProjectSource.PUHURI.value, \n",
        "        \"ext_id\": {\"$nin\": list(_PROJECTS_USERS_MAP.keys())},\n",
        "    }\n",
        "    await _collection.update_many(filter=_filter_obj, update={\n",
        "        \"$set\": {\"user_emails\": []}\n",
        "    })\n",
        "```\n"
      ],
      "id": "276dd94d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}